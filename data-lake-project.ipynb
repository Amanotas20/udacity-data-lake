{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73453800-9273-41e5-bbf4-c3a7803b9484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col,\n",
    "    date_format,\n",
    "    dayofmonth,\n",
    "    dayofweek,\n",
    "    hour,\n",
    "    monotonically_increasing_id,\n",
    "    month,\n",
    "    udf,\n",
    "    weekofyear,\n",
    "    year,\n",
    ")\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1865e84d-2178-4b08-92ae-38430118b6e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "song_data = \"s3a://udacity-dend/song_data/*/*/*/*.json\"\n",
    "log_data = \"s3a://udacity-dend/log_data/*/*/*.json\"\n",
    "output_data = \"s3a://sparkify-datalake-am/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a564bd0-e772-4519-8ca6-7b3d0f1a91dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# READ SONGS DATA\n",
    "df_song = spark.read.json(song_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab79d2f-e0e5-4269-8a8a-8406c5f36b6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract columns to create songs table\n",
    "songs_table = (df_song.select('song_id',\n",
    "                              'title',\n",
    "                              'artist_id',\n",
    "                              'year',\n",
    "                              'duration')\n",
    "                      .dropDuplicates(subset=['song_id']))\n",
    "\n",
    "songs_table.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af8cad2-5896-4647-a603-aacead1797a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write songs table to parquet files partitioned by year and artist\n",
    "(songs_table.write\n",
    "            .partitionBy('year', 'artist_id')\n",
    "            .parquet(\n",
    "                os.path.join(output_data, 'songs/song.parquet'),\n",
    "                'overwrite'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e37e77-3b35-4d7c-a64b-89dc19d79f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract columns to create artists table\n",
    "artists_table = (df_song.select('artist_id',\n",
    "                         'name',\n",
    "                         'location',\n",
    "                         'lattitude',\n",
    "                         'longitude')\n",
    "                        .dropDuplicates(subset=['artist_id']))\n",
    "artist_table.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b64c86-6155-4eaf-b033-416aa3b2e539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write artists table to parquet files\n",
    "(artists_table.write\n",
    "              .partitionBy('year', 'artist_id')\n",
    "              .parquet(\n",
    "                  os.path.join(output_data, 'artists/'),\n",
    "                  'overwrite'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4509c07-6012-4df7-b7ca-b0b00b4ff8c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# READ LOGS DATA\n",
    "df_logs = spark.read.json(log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe73e03a-1e23-4933-9557-a04e49629141",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter by actions for song plays\n",
    "df_logs = df_logs.filter(df_logs.page == 'NextSong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74aa81b-9ce7-44ac-a098-2b5fae48b93f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract columns for users table    \n",
    "users_table = (df_logs.select('userId', 'firstName',\n",
    "                        'lastName', 'gender',\n",
    "                        'level')\n",
    "                 .dropDuplicates(subset=['userId']))\n",
    "users_table.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aec7ae-1001-48aa-a35f-7e68cf12f57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write users table to parquet files\n",
    "(users_table.write\n",
    "            .parquet(\n",
    "                os.path.join(output_data, 'users/'),\n",
    "                'overwrite'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b574220-30a9-4b53-8b01-0dae2a067209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create timestamp column from original timestamp column\n",
    "get_timestamp = udf(lambda ts: str(int(int(ts)/1000)))\n",
    "df_logs = df_logs.withColumn('timestamp', get_timestamp(df_logs.ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea83f6d-1e17-4e57-9e4c-0f4e60017c7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create datetime column from original timestamp column\n",
    "get_datetime = udf(lambda dt: str(datetime.fromtimestamp(int(dt) / 1000)))\n",
    "df_logs = df_logs.withColumn('datetime', get_datetime(df_logs.ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a06e431-ffe7-416d-9cff-daa19433a965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract columns to create time table\n",
    "time_table = (df_logs.select('datetime')\n",
    "                       .withColumn('start_time', df_logs.datetime)\n",
    "                       .withColumn('hour', hour('datetime'))\n",
    "                       .withColumn('day', dayofmonth('datetime'))\n",
    "                       .withColumn('week', weekofyear('datetime'))\n",
    "                       .withColumn('month', month('datetime'))\n",
    "                       .withColumn('year', year('datetime'))\n",
    "                       .withColumn('weekday', dayofweek('datetime'))\n",
    "                       .dropDuplicates())\n",
    "time_table.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6083bce6-181a-405b-acb7-b81c204a2a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write time table to parquet files partitioned by year and month\n",
    "(time_table.write\n",
    "           .partitionBy('year', 'month')\n",
    "           .parquet(os.path.join(output_data, 'time'),\n",
    "                    'overwrite'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03b6d17-2350-49a4-b994-7717a4a823a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Join \n",
    "joined_df = df_logs.join(df_song, df_logs.artist == df_song.artist_name, 'inner')\n",
    "joined_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be9b874-036a-4dab-970f-25e9b05ab4d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "songplays_table = joined_df.select(\n",
    "        joined_df.datetime.alias('start_time'),\n",
    "        joined_df.userId.alias('user_id'),\n",
    "        joined_df.level.alias('level'),\n",
    "        joined_df.song_id.alias('song_id'),\n",
    "        joined_df.artist_id.alias('artist_id'),\n",
    "        joined_df.sessionId.alias('session_id'),\n",
    "        joined_df.location.alias('location'), \n",
    "        joined_df.userAgent.alias('user_agent'),\n",
    "        joined_df.datetime.alias('year'),\n",
    "        joined_df.datetime.alias('month')) \\\n",
    "        .withColumn('songplay_id', monotonically_increasing_id())\n",
    "\n",
    "songplays_table.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab221b10-f676-4261-accd-d832b60cb519",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write songplays table to parquet files partitioned by year and month\n",
    "(songplays_table.write\n",
    "                .partitionBy('year', 'month')\n",
    "                .parquet(os.path.join(output_data,\n",
    "                                      'songplays'),\n",
    "                         'overwrite'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
